{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "536430fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8aa80",
   "metadata": {},
   "source": [
    "## Neural network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7e6210",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7c/2n3ws68d3rb2xw9b37v1zkxm0000gn/T/ipykernel_92086/3992542782.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def build_net(params, activation=tf.nn.relu):\n",
    "    def model(X, training=True):\n",
    "        for w, b in params[:-1]:\n",
    "            X = dense(X, w, b, activation)\n",
    "        # final linear layer\n",
    "        X = dense(X, *params[-1])\n",
    "        y_pred, y_log_var = tf.unstack(X, axis=-1)\n",
    "        y_var = tf.exp(y_log_var)\n",
    "        if training:\n",
    "            return tfp.distributions.Normal(loc=y_pred, scale=tf.sqrt(y_var))\n",
    "        return y_pred, y_var\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "972a89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnn_log_prob_fn(X, y, params, get_mean=False):\n",
    "    \"\"\"Compute log likelihood of predicted labels y given features X and params.\n",
    "    Args:\n",
    "        X (np.array): 2d feature values.\n",
    "        y (np.array): 1d labels (ground truth).\n",
    "        params (list): [[w1, b1], ...] containing 2d/1d arrays for weights/biases.\n",
    "        get_mean (bool, optional): Whether to return the mean log\n",
    "            probability over all labels for diagnostics, e.g. to\n",
    "            compare train and test set performance.\n",
    "    Returns:\n",
    "        tf.tensor: Sum or mean of log probabilities of all labels.\n",
    "    \"\"\"\n",
    "    net = build_net(params)\n",
    "    labels_dist = net(X)\n",
    "    if get_mean:\n",
    "        return tf.reduce_mean(labels_dist.log_prob(y))\n",
    "    return tf.reduce_sum(labels_dist.log_prob(y))\n",
    "\n",
    "\n",
    "def bnn_log_prob_fn(x, y, params):\n",
    "    model = get_model(params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84085331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_log_prob_fn(w_prior, b_prior, params):\n",
    "    log_prob = 0\n",
    "    for w, b in params:\n",
    "        log_prob += tf.reduce_sum(w_prior.log_prob(w))\n",
    "        log_prob += tf.reduce_sum(b_prior.log_prob(b))\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6288378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    # Subdivide lst into successive n-sized chunks.\n",
    "    return [lst[i : i + n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35b787e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob_fn_factory(w_prior, b_prior, X_train, y_train):\n",
    "    # This signature is forced by TFP's HMC kernel which calls log_prob_fn(*chains).\n",
    "    def target_log_prob_fn(*params):\n",
    "        if not isinstance(params[0], (list, tuple)):\n",
    "            params = chunks(params, 2)\n",
    "        log_prob = prior_log_prob_fn(w_prior, b_prior, params)\n",
    "        log_prob += bnn_log_prob_fn(X_train, y_train, params)\n",
    "        return log_prob\n",
    "    return target_log_prob_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e4cf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracer_factory(X, y):\n",
    "    return lambda params: ft.partial(bnn_log_prob_fn, X, y, get_mean=True)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2d14c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_initial_state(w_prior, b_prior, nodes_per_layer, overdisp=1.0):\n",
    "    \"\"\"Draw random samples for weights and biases of a NN according to some\n",
    "    specified priors. distributions. This set of parameter values can serve as a\n",
    "    starting point for MCMC or gradient descent training.\n",
    "    \"\"\"\n",
    "    init_state = []\n",
    "    for n1, n2 in zip(nodes_per_layer, nodes_per_layer[1:]):\n",
    "        w_shape, b_shape = [n1, n2], n2\n",
    "        # Use overdispersion > 1 for better R-hat statistics.\n",
    "        w = w_prior.sample(w_shape) * overdisp\n",
    "        b = b_prior.sample(b_shape) * overdisp\n",
    "        init_state.append([tf.Variable(w), tf.Variable(b)])\n",
    "    return init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054af29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad975d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: tf.math.sin(x)\n",
    "\n",
    "n_train = 3\n",
    "x_train = tf.random.normal(shape=(n_train, 1), mean=0., stddev=2.)\n",
    "y_train = f(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4676390",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_prior = tfd.Normal(loc=0., scale=0.2)\n",
    "b_prior = tfd.Normal(loc=0., scale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c003bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68a965e",
   "metadata": {},
   "source": [
    "## HMC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96d026f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train_nn(X_train, y_train, nodes_per_layer, epochs=100):\n",
    "    \"\"\"Pre-train NN to get good starting point for HMC.\n",
    "    Args:\n",
    "        nodes_per_layer (list): the number of nodes in each dense layer\n",
    "        X_train (Tensor or np.array): training samples\n",
    "        y_train (Tensor or np.array): training labels\n",
    "    Returns:\n",
    "        Tensor: list of arrays specifying the weights of the trained network\n",
    "        model: Keras Sequential model\n",
    "    \"\"\"\n",
    "    layers = [tf.keras.layers.Dense(n, activation=\"relu\") for n in nodes_per_layer]\n",
    "    layers[-1].activation = tf.identity  # Make last layer linear.\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    return model.get_weights(), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbbbb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def sample_chain(*args, **kwargs):\n",
    "    \"\"\"Compile static graph for tfp.mcmc.sample_chain to improve performance.\"\"\"\n",
    "    return tfp.mcmc.sample_chain(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7806f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd044ff99d3af02f09e383a3ffce177a5afc09212563ff719d1be2a4f8771c8cd81"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
