\babel@toc {UKenglish}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {8.1}{\ignorespaces The table shows a selection of models that is used for benchmarking purposes in this chapter. For each model, 1000 sampled networks were sampled to collectively represent each BNN model. We performed 1000 pretraining epochs with a batch size of 32 using the ADAM optimizer. We used 2500 warm-up steps (80\% adaptation steps first, followed by 20\% burn-in steps). For every sampled network, we skipped 10 samples. The kernel used for each model was the NUTS kernel with a maximum of $L = 4096$ Leapfrog steps. The number of nodes per layer is shown in the ``Layers'' column. \relax }}{46}{table.caption.20}%
\addvspace {10\p@ }
