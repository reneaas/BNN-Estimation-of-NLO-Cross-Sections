\babel@toc {UKenglish}{}
\contentsline {chapter}{Introduction}{1}{chapter*.7}%
\contentsline {chapter}{\numberline {1}The Physics Problem}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Computation of Beyond the Standard Model Cross Sections}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Bayesian Regression as a Substitute}{4}{section.1.2}%
\contentsline {chapter}{\numberline {2}Bayesian Formulation of Machine Learning}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}The Core of Machine Learning}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Loss Functions}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Regularization}{6}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Optimization}{6}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Bayes' theorem}{6}{section.2.2}%
\contentsline {section}{\numberline {2.3}Bayesian Framework for Machine Learning}{7}{section.2.3}%
\contentsline {section}{\numberline {2.4}Bayesian Inference}{8}{section.2.4}%
\contentsline {chapter}{\numberline {3}Markov Chain Monte Carlo}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Expectation Values and the Typical Set}{11}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Typical Set}{11}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}The Target Density and Bayesian Applications}{12}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Markov Chains and Markov Transitions}{12}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Ideal Markov Chains}{13}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Pathologies}{13}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Geometric Ergodicity and Convergence Diagnostics}{13}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Metropolis-Hastings}{13}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}The Proposal Distribution}{14}{subsection.3.3.1}%
\contentsline {section}{\numberline {3.4}Gibbs Sampling}{15}{section.3.4}%
\contentsline {chapter}{\numberline {4}Hamiltonian Monte Carlo}{17}{chapter.4}%
\contentsline {section}{\numberline {4.1}Hamiltonian Dynamics}{17}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Leapfrog integration}{18}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Generating a Proposal State}{19}{section.4.2}%
\contentsline {section}{\numberline {4.3}The Potential Energy Function in Bayesian Machine Learning Applications}{21}{section.4.3}%
\contentsline {section}{\numberline {4.4}Limitations of Hamiltonian Monte Carlo}{21}{section.4.4}%
\contentsline {chapter}{\numberline {5}Adaptive Hamiltonian Monte Carlo}{23}{chapter.5}%
\contentsline {section}{\numberline {5.1}The No-U-Turn Sampler}{23}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Generation of States and the Stopping Criterion}{24}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Selecting Candidate Points}{25}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Efficiently Implementing the No-U-Turn Sampler}{26}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Computational Cost of The No-U-Turn Sampler}{27}{subsection.5.1.4}%
\contentsline {section}{\numberline {5.2}Adapting the Step Size}{27}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Adapting a General Parameter Using a Dual Averaging Scheme}{27}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Setting the Step Size in Hamiltonian Monte Carlo}{28}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Adapting the Step Size with the No-U-Turn Sampler}{28}{subsection.5.2.3}%
\contentsline {subsection}{\numberline {5.2.4}Generalizing the Tuning Algorithm}{29}{subsection.5.2.4}%
\contentsline {chapter}{\numberline {6}Bayesian Neural Networks}{31}{chapter.6}%
\contentsline {section}{\numberline {6.1}Neural Networks}{31}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Basic Mathematical Structure}{31}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Backpropagation}{32}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Regularization in Neural Networks}{33}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}Activation Functions}{34}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Sigmoid and Tanh}{34}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}ReLU}{34}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Swish}{34}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Bayesian learning of Neural Networks using Monte Carlo Samplers}{34}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}What \textit {is} Bayesian learning of Neural Networks?}{35}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}The Potential Energy Function of Neural Networks}{35}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Practical Training of Bayesian Neural Networks}{35}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Training Algorithm of Bayesian Neural Networks}{36}{subsection.6.3.4}%
\contentsline {chapter}{\numberline {7}Numerical Experiments}{39}{chapter.7}%
\contentsline {section}{\numberline {7.1}The Dataset}{39}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Data Generation}{39}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Data Scaling and Transformations}{39}{subsection.7.1.2}%
\contentsline {subsection}{\numberline {7.1.3}Data Splitting}{39}{subsection.7.1.3}%
\contentsline {section}{\numberline {7.2}Methodology}{40}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Implementation}{40}{subsection.7.2.1}%
\contentsline {subsection}{\numberline {7.2.2}Selection of Models and Hyperparameters}{40}{subsection.7.2.2}%
\contentsline {subsection}{\numberline {7.2.3}Performance Metrics}{40}{subsection.7.2.3}%
\contentsline {subsubsection}{\numberline {7.2.3.1}Relative Error}{41}{subsubsection.7.2.3.1}%
\contentsline {subsubsection}{\numberline {7.2.3.2}Standardized Residuals}{41}{subsubsection.7.2.3.2}%
\contentsline {section}{\numberline {7.3}Results}{41}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Computational Performance}{41}{subsection.7.3.1}%
\contentsline {subsubsection}{\numberline {7.3.1.1}CPU v. GPU Performance}{41}{subsubsection.7.3.1.1}%
\contentsline {subsubsection}{\numberline {7.3.1.2}Prediction Time}{41}{subsubsection.7.3.1.2}%
\contentsline {subsubsection}{\numberline {7.3.1.3}Loading Times}{43}{subsubsection.7.3.1.3}%
\contentsline {subsection}{\numberline {7.3.2}Posterior Distribution of Weights}{43}{subsection.7.3.2}%
\contentsline {subsection}{\numberline {7.3.3}Benchmarks of Hyperparameters}{47}{subsection.7.3.3}%
\contentsline {subsubsection}{\numberline {7.3.3.1}The Effect of Number of Burn-in Steps and Step Size Adaptation}{47}{subsubsection.7.3.3.1}%
\contentsline {subsubsection}{\numberline {7.3.3.2}The Effect of Pretraining}{47}{subsubsection.7.3.3.2}%
\contentsline {subsubsection}{\numberline {7.3.3.3}Effect of Number of Parameters}{52}{subsubsection.7.3.3.3}%
\contentsline {subsection}{\numberline {7.3.4}Neutralino-Neutralino Cross Sections}{53}{subsection.7.3.4}%
\contentsline {subsubsection}{\numberline {7.3.4.1}Predictive Distributions}{53}{subsubsection.7.3.4.1}%
\contentsline {chapter}{Conclusion}{58}{chapter*.32}%
\contentsline {chapter}{Appendices}{59}{section*.33}%
\contentsline {chapter}{Appendix A}{61}{appendix*.34}%
\contentsline {section}{\numberline {A.1}Appendix 1 title }{61}{section.Alph0.1}%
