\babel@toc {UKenglish}{}
\contentsline {chapter}{Introduction}{1}{chapter*.5}%
\contentsline {chapter}{\numberline {1}The Physics Problem}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Bayesian Formulation of Machine Learning}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}The Core of Machine Learning}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Loss Functions}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Regularization}{6}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Optimization}{6}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Bayes' theorem}{6}{section.2.2}%
\contentsline {section}{\numberline {2.3}Bayesian Framework for Machine Learning}{7}{section.2.3}%
\contentsline {section}{\numberline {2.4}Bayesian Inference}{8}{section.2.4}%
\contentsline {chapter}{\numberline {3}Markov Chain Monte Carlo}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Expectation Values and the Typical Set}{11}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Typical Set}{11}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}The Target Density and Bayesian Applications}{12}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Markov Chains and Markov Transitions}{12}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Ideal Markov Chains}{13}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Pathologies}{13}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Geometric Ergodicity and Convergence Diagnostics}{13}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Metropolis-Hastings}{13}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}The Proposal Distribution}{14}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Random Walk Metropolis}{14}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Gibbs Sampling}{14}{section.3.4}%
\contentsline {chapter}{\numberline {4}Hamiltonian Monte Carlo}{17}{chapter.4}%
\contentsline {section}{\numberline {4.1}Hamiltonian Dynamics}{17}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Leapfrog integration}{18}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Generating a Proposal State}{18}{section.4.2}%
\contentsline {section}{\numberline {4.3}The Potential Energy Function in Bayesian ML Applications}{20}{section.4.3}%
\contentsline {section}{\numberline {4.4}Limitations of HMC}{20}{section.4.4}%
\contentsline {chapter}{\numberline {5}The No-U-Turn Sampler}{23}{chapter.5}%
\contentsline {section}{\numberline {5.1}Preliminary definitions}{23}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Generation of Candidate Points and Stopping Criterion}{24}{subsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.1.1}Choosing candidate points}{24}{subsubsection.5.1.1.1}%
\contentsline {section}{\numberline {5.2}The Naive NUTS Algorithm}{25}{section.5.2}%
\contentsline {section}{\numberline {5.3}Efficient NUTS}{26}{section.5.3}%
\contentsline {section}{\numberline {5.4}Dual-Averaging Step Size Adaptation}{27}{section.5.4}%
\contentsline {section}{\numberline {5.5}NUTS with Dual-Averaging Step Size Adaptation}{27}{section.5.5}%
\contentsline {chapter}{\numberline {6}Bayesian Learning for Neural Networks}{29}{chapter.6}%
\contentsline {section}{\numberline {6.1}Neural Networks}{29}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Basic Mathematical Structure}{29}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Backpropagation}{30}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Loss Function for Regression}{30}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Regularization in Neural Networks}{31}{subsection.6.1.4}%
\contentsline {section}{\numberline {6.2}Activation Functions}{32}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Sigmoid}{32}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}ReLU}{32}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Swish}{32}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Bayesian Framework for Neural Networks}{32}{section.6.3}%
\contentsline {section}{\numberline {6.4}Bayesian learning using HMC}{33}{section.6.4}%
\contentsline {chapter}{\numberline {7}Numerical Experiments}{35}{chapter.7}%
\contentsline {section}{\numberline {7.1}The Dataset}{35}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Data Generation}{35}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Data Scaling and Transformations}{35}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Performance Metrics}{35}{section.7.2}%
\contentsline {section}{\numberline {7.3}Results}{35}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Benchmarks of Hyperparameters}{35}{subsection.7.3.1}%
\contentsline {subsubsection}{\numberline {7.3.1.1}Baseline Model}{35}{subsubsection.7.3.1.1}%
\contentsline {subsubsection}{\numberline {7.3.1.2}Pretraining}{35}{subsubsection.7.3.1.2}%
\contentsline {subsubsection}{\numberline {7.3.1.3}Burn-in length}{35}{subsubsection.7.3.1.3}%
\contentsline {subsubsection}{\numberline {7.3.1.4}Number of model parameters}{35}{subsubsection.7.3.1.4}%
\contentsline {subsection}{\numberline {7.3.2}Neutralino-Neutralino Cross Sections}{35}{subsection.7.3.2}%
\contentsline {chapter}{\numberline {8}Discussion}{37}{chapter.8}%
\contentsline {chapter}{Conclusion}{40}{chapter*.16}%
\contentsline {chapter}{Appendices}{41}{section*.17}%
\contentsline {chapter}{Appendix A}{43}{appendix*.18}%
\contentsline {section}{\numberline {A.1}Appendix 1 title }{43}{section.Alph0.1}%
