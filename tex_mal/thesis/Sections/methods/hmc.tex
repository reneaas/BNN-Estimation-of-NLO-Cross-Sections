In this chapter, we will study the details of the Hamiltonian Monte Carlo (HMC) method.
It is a Markov Chain Monte Carlo (MCMC) sampling technique that merges Gibbs sampling, Hamiltonian dynamics with a final Metropolis-Hastings update.
It avoids random walk behaviour with a systematical exploration of the state space 
and generates successive samples with smaller correlation. We will begin with a survey of Lagrangian and Hamiltonian dynamics followed by a description of
the \textit{Leapfrog} integrator which is used to simulate the Hamiltonian systems. Once these are established, we will summarize the 
HMC method in a generic manner - applicable to any continuous distribution. Moreoever, we will discuss important properties like conservation of the Hamiltonian
and local phase space volume.


\section{Hamiltonian dynamics}\label{sec:hamiltonian_dynamics}
Hamiltonian dynamics \cite{classical_mechanics} plays a central part in the HMC algorithm. 
For completeness, we will first survey Lagrangian mechanics from which we derive the Hamiltonian. 
The Hamiltonian then lays the foundation for Hamiltonian dynamics.

\subsection{Lagrangian Mechanics}
Assume a set of \textit{generalized coordinates} $q = (q_1, ..., q_n)$. Generally, the Lagrangian can be written as
\begin{equation}
  L(q, \dot{q}, t) = K(q, \dot{q}, t) - V(q, \dot{q}, t),
\end{equation}
where $K$ is the kinetic energy and $V$ is the potential energy of the system. We shall restrict the treatment to the case where there is no explicit dependence on time $t$. The solutions $q(t)$ can be found by solving the \textit{Euler--Lagrange} equations given by
\begin{equation}
  \dv{}{t}\pdv{L}{\dot{q}_i} - \pdv{L}{q_i} = 0.
\end{equation}

\subsection{Hamiltonian Mechanics}
The Hamiltonian is constructed by the Legendre transformation,
\begin{equation}
  H(q, p, t) = \sum_i p_i \dot{q}_i(q, p) - L(q, \dot{q}(q, p), t),
\end{equation}
where
\begin{equation}
  p_i = \pdv{L}{\dot{q}_i}.
\end{equation}
The equations of motion, known as \textit{Hamilton's} equations, are given by
\begin{equation}\label{eq:eom}
  \dv{q_i}{t} = \pdv{H}{p_i}, \qquad \dv{p_i}{t} = - \pdv{H}{q_i}.
\end{equation}

For the purpose of utilizing this framework in the context of HMC, it's assumed that the form of the Lagrangian is
\begin{equation}
  L(q, \dot{q}) = K(\dot{q}) - V(q),
\end{equation}
where
\begin{equation}\label{eq:kinetic_energy}
  K(\dot{q}) = \sum_i \frac{1}{2}m_i\dot{q}^2_i.
\end{equation}
The generalized momentum of coordinate $q_i$ is
\begin{equation}
  p_i = \pdv{K}{\dot{q}_i} = m\dot{q}_i,
\end{equation}
from which it follows that the Legendre transformed kinetic energy can be written as
\begin{equation}\label{eq:kinetic_energy}
  K(p) = \sum_i \frac{p_i^2}{2m_i}.
\end{equation}
Finally, we can write down the Hamiltonian as
\begin{equation}\label{eq:hamiltonian}
  H(q, p) = K(p) + V(q) = \sum_i \frac{p_i^2}{2m_i} + V(q).
\end{equation}
From Hamilton's equations in eq.~\ref{eq:eom}, we can easily show that the Hamiltonian is conserved in time $t$ by
\begin{equation}
  \dv{H}{t} = \sum_i\left(\dv{q_i}{t}\pdv{H}{q_i} + \dv{p_i}{t}\pdv{H}{p_i}  \right)
  = \sum_i\left(\pdv{H}{p_i}\pdv{H}{q_i} - \pdv{H}{q_i}\pdv{H}{p_i}  \right) = 0.
\end{equation}
This motives the need for a symplectic integrator, which we will discuss next.

\subsection{Leapfrog integration}
To run one step of HMC, we need to compute the time evolution of a Hamiltonian system of the form discussed in the former section,
where the neural network parameters will play the role as the generalized coordinates $q$.
The common choice of algorithm to integrate the equations of motion in eq.~\eqref{eq:eom} is \textit{Leapfrog} integration \cite{leapfrog}. This integrator is \textit{symplectic}, which means it conserves local volumes in phase space. This effectively translates to an approximately conserved value of $H(q,p)$ throughout a simulation, with slight oscillations about a mean value.

Assume we approximate the true coordinates and momenta by $(\hat{q}, \hat{p})$. A single Leapfrog integration step can then be written as in algorithm \ref{algo:leapfrog}. Here $h$ represents the stepsize used in the algorithm.
\begin{figure}[H]
	\begin{algorithm}[H]
		\caption{Leapfrog integration (single step)}\label{algo:leapfrog}
		\begin{algorithmic}
      \Procedure{LEAPFROG}{$q, p, \lambda$}
			\State 1. $\hat{p}_i(t + h/2) = \hat{p}_i(t) - \lambda\frac{h}{2}\pdv*{V(\hat{q}(t))}{q_i} $\\
			\State 2. $\hat{q_i}(t+h) = \hat{q}_i(t) + \lambda\frac{h}{m_i}\hat{p}_i(t+h/2)$\\
			\State 3. $\hat{p_i}(t+h) = \hat{p}_i(t + h/2) -  \lambda\frac{h}{2}\pdv*{V(\hat{q}(t+h))}{q_i}$
      \EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{figure}

\subsection{Conservation of local phase-space volume}

\section{Hamiltonian Monte Carlo}
Hamiltonian Monte Carlo is largely developed and expanded upon by Radford Neal \cite{hmc}. The probability distribution to sample from
is expressed in terms the Canonical distribution
\begin{equation}
  P(q) \propto \exp(-V(q)),
\end{equation}
where $q$ represents the parameters of the model. $V(q)$ can then always be expressed as
\begin{equation}
  V(q) = -\log Z - \log P(q)
\end{equation}
for some normalization constant $Z$. 
This constant plays no actual role in the sampling procedure as we only need to compute the difference $V(q') - V(q)$ at two points $q'$ and $q$.
We also need the gradient of $V$ with respect to $q$ where the constant term vanishes.
To utilize the framework of Hamiltonian dynamics explained in section \ref{sec:hamiltonian_dynamics}, we introduce momentum variables
$p_i$ such that we can express the total Hamiltonian as
\begin{equation}
  H(q, p) = K(p) + V(q),
\end{equation}
with a corresponding canonical distribution over phase-space
\begin{equation}
  P(q, p) \propto \exp\left(-H(q,p)\right).
\end{equation}
The HMC scheme is summarized in algorithm \ref{algo:hmc}.
\begin{figure}[H]
	\begin{algorithm}[H]
		\caption{Hamiltonian Monte Carlo}\label{algo:hmc}
		\begin{algorithmic}
      \Procedure{HMC}{$L, q, p$}
      \State Sample $u \sim U(0,1)$.
      \State $\lambda = 1 \qq{if} u \geq 1/2 \qq{else} \lambda = -1$
      \State $(q^*, p^*) \leftarrow (q, p)$    \Comment{Start from initial state.}
      \State $p^* \leftarrow \text{GIBBS}(p^*)$
      \For{$l = 1, ..., L$} \Comment{$L$ Leapfrog steps.}
        \State $(q^*, p^*) \leftarrow$ LEAPFROG$(q^*, p^*, \lambda)$
      \EndFor
      \State $P = \min \left(1, \exp\left[-\left(H(q^*,p^*) - H(q, p)\right)\right]\right)$
      \State Sample $u \sim U(0,1)$ \Comment{Uniform distribution on $(0,1)$.}
      \If {$P \geq u$}
        \State $(q, p) \leftarrow (q^*, p^*)$ \Comment{Accept proposed state.}
      \Else
        \State $(q, p) \leftarrow (q, p)$ \Comment{Reject proposed state.}
      \EndIf
      \EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{figure}

