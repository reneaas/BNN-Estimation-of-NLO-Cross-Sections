In this chapter, I'll explain the details of the Hamiltonian Monte Carlo (HMC) method.
It's a Monte Carlo (MC) sampling technique that merges Gibbs sampling and a modified version of Metropolis sampling
with Hamiltonian dynamics. It avoids the random walk behaviour of the Metropolis algorithm
and generates successive samples with smaller correlation. In this chapter, the first thing I'll discuss is Markov chains.
From that, follows an outline of Gibbs- and Metropolis sampling. After that, I'll deal with Hamiltonian dynamics before I bring it all together
to form the Hamiltonian Monte Carlo algorithm for sampling. This forms the basis for the practical Bayesian learning of the neural networks studied in this thesis.

\section{Markov Chains}
The treatment of Markov chains largely follows the presentation in \cite{markov_chains}. A Markov process is a scheme that from a given state $\mu$ generates a new state $\nu$ with a \textit{transition} probability $P(\mu \to \nu)$. A Makrov process has the following properties
\begin{itemize}
  \item The transition probabilities $P(\mu \to \nu)$ are time-independent.
  \item $P(\mu \to \nu)$ only depend on the states $\mu$ and $\nu$.
  \item The transition $\mu \to \mu$ is allowed, thus $P(\mu \to \mu) > 0$.
  \item The transition probabilties must sum to unity, hence $\sum_\nu P(\mu \to \nu) = 1$.
\end{itemize}
A Markov chain is a sequence of states generated by a Markov process.
The objective is to generate a sequence of states who's occurence is accordance with the true underlying probability distribution. To achieve this, we impose two additional principles, \textit{ergodicity} and \textit{detailed balance}. 
\begin{enumerate}
  \item \textbf{Ergodicity}: Any state $\nu$ can be reached from any state $\mu$ given a long enough Markov chain.
  \item \textbf{Detailed balance}: On average, the makes the transition $\mu \to \nu$ just as often as $\nu \to \mu$. This statement is equivalent to $p_\mu P(\mu \to \nu) = p_\nu P(\nu \to \mu)$, where $p_\mu$ and $p_\nu$ is the probability of the states $\mu$ and $\nu$, respectively.
\end{enumerate}

\section{Gibbs sampling}
Gibbs sampling \cite{gibbs} is a sampling technique for multi-dimensional parameters $\gamma \in \mathbb{R}^d$, for $d > 1$.
Suppose $\gamma^{(t)}$ is the parameters at iteration $t$. Then the parameters $\gamma^{(t+1)}$ at iteration $t+1$ are generated from $\gamma^{(t)}$ by the algorithm

\begin{figure}[H]
  \begin{algorithm}[H]
    \caption{Gibbs sampling}
    \begin{algorithmic}
      \State Sample $\gamma^{(t+1)}_1 \sim P(\gamma_1|\gamma_2^{(t)},...,\gamma_d^{(t)})$ \\
      \State Sample $\gamma^{(t+1)}_2 \sim P(\gamma_2|\gamma_1^{(t+1)},...,\gamma_d^{(t)})$\\
      \State $\vdots$ \qquad  \qquad $\vdots$ \qquad  \qquad $\vdots$ \qquad \qquad $\vdots$\\
      \State Sample $\gamma^{(t+1)}_d \sim P(\gamma_d|\gamma_1^{(t+1)},...,\gamma_{d-1}^{(t+1)})$
    \end{algorithmic}
  \end{algorithm}
\end{figure}



\section{The Metropolis algorithm}
The Metropolis algorithm \cite{metropolis} is a sampling algorithm based on random walks in parameter space. Albeit efficient for some
problems, it's not a suitable sampling technique in the context of neural networks. However, a rudimentary understanding of the algorithm will be useful before we embark upon the HMC sampling algorithm.


\section{Hamiltonian dynamics}
Hamiltonian dynamics \cite{classical_mechanics} plays a central part in the HMC algorithm. For completeness, I'll first give a brief survey of Lagrangian mechanics from which we derive the Hamiltonian. The Hamiltonian then lays the foundation for the Hamiltonian dynamics.

\subsection{Lagrangian Mechanics}
Assume a set of \textit{generalized coordinates} $q = (q_1, ..., q_n)$. Generally, the Lagrangian can be written as
\begin{equation}
  L(q, \dot{q}, t) = K(q, \dot{q}, t) - V(q, \dot{q}, t),
\end{equation}
where $K$ is the kinetic energy and $V$ is the potential energy of the system. I'll restrict the treatment to the case where there's no explicit dependence on time $t$. The solutions $q(t)$ can be found by solving the Euler-Lagrange equations given by

\begin{equation}
  \dv{}{t}\pdv{L}{\dot{q}_i} - \pdv{L}{q_i} = 0.
\end{equation}

\subsection{Hamiltonian Mechanics}
The Hamiltonian is constructed by the Legendre transformation,
\begin{equation}
  H(q, p, t) = \sum_i p_i \dot{q}_i(p_i) - L(q, \dot{q}(p), t),
\end{equation}
where
\begin{equation}
  p_i = \pdv{L}{\dot{q}_i}
\end{equation}
The equations of motion, known as \textit{Hamilton's} equations, are given by
\begin{equation}
  \dv{p_i}{t} = \pdv{H}{p_i}, \qquad \dv{p_i}{t} = - \pdv{H}{q_i}.
\end{equation}
For the purpose of utilizing this framework in the context of HMC, it's assumed that the form of the Lagrangian is
\begin{equation}
  L(q, \dot{q}) = K(\dot{q}) - V(q),
\end{equation}
where
\begin{equation}
  K(\dot{q}) = \sum_i \frac{1}{2}m_i\dot{q}^2_i.
\end{equation}
In this case, the Hamiltonian gets the simple form
\begin{equation}
  H(q, p) = K(p) + V(q) = \sum_i \frac{p_i^2}{2m_i} + V(q).
\end{equation}

\subsection{Leapfrog integration}
To run one step of HMC, we need to simulate a Hamiltonian system of the form discussed in the former section.
The common choice of algorithm to integrate the equations is \textit{leapfrog} integration \cite{leapfrog}. This integrator is \textit{symplectic}, which means it conserves local volumes in phase space. This effectively translates to an approximately conserved value of $H(q,p)$ throughout a simulation, with slight oscillations about a mean value.

Assume we approximate the true coordinates and momenta by $(\hat{q}, \hat{p})$. A single leapfrog integration step can then be written as
\begin{figure}[H]
	\begin{algorithm}[H]
		\caption{Leapfrog integration (single step)}
		\begin{algorithmic}
			\State 1. $\hat{p}_i(t + h/2) = \hat{p}_i(t) - \frac{h}{2}\pdv{V(q(t))}{q_i} $\\
			\State 2. $\hat{q_i}(t+h) = \hat{q}_i(t) + h\frac{p_i(t+h/2)}{m_i}$\\
			\State 3. $\hat{p_i}(t+h) = \hat{p}_i(t + h/2) -  \frac{h}{2}\pdv{V(q(t+h))}{q_i}$
		\end{algorithmic}
	\end{algorithm}
\end{figure}

\section{Hamiltonian Monte Carlo}
Hamiltonian Monte Carlo \cite{hmc} is largely developed and expanded upon by R. Neal.
