\babel@toc {UKenglish}{}
\contentsline {chapter}{Introduction}{1}{chapter*.4}%
\contentsline {chapter}{\numberline {1}Machine Learning: Preliminaries}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Basic concepts in regression}{3}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Bias-variance trade-off}{3}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}Loss functions}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Regularization}{4}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Optimization}{4}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Gradient descent}{4}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Stochastic gradient descent}{4}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Gradient Descent With Momentum}{5}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}RMSprop}{5}{subsection.1.3.4}%
\contentsline {section}{\numberline {1.4}Data preprocessing}{5}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Data splitting}{5}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Data scaling}{5}{subsection.1.4.2}%
\contentsline {section}{\numberline {1.5}Optimization formulated in terms of Bayesian statistics}{5}{section.1.5}%
\contentsline {chapter}{\numberline {2}Markov Chain Monte Carlo}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Markov Chain Monte Carlo}{7}{section.2.1}%
\contentsline {section}{\numberline {2.2}Gibbs sampling}{8}{section.2.2}%
\contentsline {section}{\numberline {2.3}Metropolis-Hastings}{8}{section.2.3}%
\contentsline {section}{\numberline {2.4}Convergence diagnostics and strategies}{9}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Burn-in}{9}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Autocorrelation}{9}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Mixing}{9}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}The Potential Scale Reduction Factor $\hat {R}$}{9}{subsection.2.4.4}%
\contentsline {chapter}{\numberline {3}Hamiltonian Monte Carlo}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Hamiltonian dynamics}{11}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Lagrangian Mechanics}{11}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Hamiltonian Mechanics}{11}{subsection.3.1.2}%
\contentsline {subsection}{\numberline {3.1.3}Leapfrog integration}{12}{subsection.3.1.3}%
\contentsline {subsection}{\numberline {3.1.4}Conservation of local phase-space volume}{13}{subsection.3.1.4}%
\contentsline {section}{\numberline {3.2}Hamiltonian Monte Carlo}{13}{section.3.2}%
\contentsline {chapter}{\numberline {4}The No U-Turn Sampler}{15}{chapter.4}%
\contentsline {chapter}{\numberline {5}Bayesian Learning for Neural Networks}{17}{chapter.5}%
\contentsline {section}{\numberline {5.1}Neural Networks}{17}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Basic mathematical structure}{17}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Backpropagation}{18}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Loss function for regression}{18}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Regularization in Neural Networks}{19}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}Activation functions}{20}{subsection.5.1.5}%
\contentsline {section}{\numberline {5.2}Bayesian inference}{20}{section.5.2}%
\contentsline {section}{\numberline {5.3}Bayesian framework for neural networks}{20}{section.5.3}%
\contentsline {section}{\numberline {5.4}Sources of uncertainty}{21}{section.5.4}%
\contentsline {section}{\numberline {5.5}Bayesian learning using HMC}{21}{section.5.5}%
\contentsline {chapter}{Conclusion}{24}{chapter*.12}%
\contentsline {chapter}{Appendices}{25}{section*.13}%
\contentsline {chapter}{Appendix A}{27}{appendix*.14}%
\contentsline {section}{\numberline {A.1}Appendix 1 title }{27}{section.Alph0.1}%
