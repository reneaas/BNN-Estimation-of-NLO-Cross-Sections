\babel@toc {UKenglish}{}
\contentsline {chapter}{Introduction}{1}{chapter*.4}%
\contentsline {chapter}{\numberline {1}The Physics Problem}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Machine Learning: Preliminaries}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Basic Concepts in Regression}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Bias-Variance Trade-Off}{5}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}Loss Functions}{6}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Regularization}{6}{subsection.2.2.1}%
\contentsline {section}{\numberline {2.3}Optimization}{6}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Gradient Descent}{6}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Stochastic Gradient Descent}{7}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Gradient Descent with Momentum}{7}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}RMSprop}{7}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}ADAM}{7}{subsection.2.3.5}%
\contentsline {section}{\numberline {2.4}Bayesian Formulation}{8}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Bayes' Rule}{8}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Bayesian Viewpoint of Optimization}{8}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Bias-Variance Trade-Off Vanishes}{8}{subsection.2.4.3}%
\contentsline {chapter}{\numberline {3}Markov Chain Monte Carlo}{9}{chapter.3}%
\contentsline {section}{\numberline {3.1}Expectation Values and the Typical Set}{9}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Typical Set}{9}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}Markov Chains and Markov Transitions}{10}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Ideal Markov Chains}{10}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Pathologies}{11}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Geometric Ergodicity}{11}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Metropolis-Hastings}{11}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Random Walk Metropolis}{12}{subsection.3.3.1}%
\contentsline {section}{\numberline {3.4}Gibbs Sampling}{12}{section.3.4}%
\contentsline {chapter}{\numberline {4}Hamiltonian Monte Carlo}{13}{chapter.4}%
\contentsline {section}{\numberline {4.1}Gradient-Informed Exploration}{13}{section.4.1}%
\contentsline {chapter}{\numberline {5}The No-U-Turn Sampler}{15}{chapter.5}%
\contentsline {section}{\numberline {5.1}Preliminary definitions}{15}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Generation of Candidate Points and Stopping Criterion}{16}{subsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.1.1}Choosing candidate points}{16}{subsubsection.5.1.1.1}%
\contentsline {section}{\numberline {5.2}The Naive NUTS Algorithm}{17}{section.5.2}%
\contentsline {section}{\numberline {5.3}Efficient NUTS}{18}{section.5.3}%
\contentsline {section}{\numberline {5.4}Dual-Averaging Step Size Adaptation}{19}{section.5.4}%
\contentsline {section}{\numberline {5.5}NUTS with Dual-Averaging Step Size Adaptation}{19}{section.5.5}%
\contentsline {chapter}{\numberline {6}Bayesian Learning for Neural Networks}{21}{chapter.6}%
\contentsline {section}{\numberline {6.1}Neural Networks}{21}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Basic Mathematical Structure}{21}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Backpropagation}{22}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Loss Function for Regression}{22}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Regularization in Neural Networks}{23}{subsection.6.1.4}%
\contentsline {section}{\numberline {6.2}Activation Functions}{24}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Sigmoid}{24}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}ReLU}{24}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Swish}{24}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Bayesian Inference}{24}{section.6.3}%
\contentsline {section}{\numberline {6.4}Bayesian Framework for Neural Networks}{25}{section.6.4}%
\contentsline {section}{\numberline {6.5}Bayesian learning using HMC}{26}{section.6.5}%
\contentsline {chapter}{\numberline {7}Numerical Experiments}{27}{chapter.7}%
\contentsline {section}{\numberline {7.1}The Dataset}{27}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Data Generation}{27}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Data Scaling and Transformations}{27}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Performance Metrics}{27}{section.7.2}%
\contentsline {section}{\numberline {7.3}Results}{27}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Benchmarks of Hyperparameters}{27}{subsection.7.3.1}%
\contentsline {subsubsection}{\numberline {7.3.1.1}Baseline Model}{27}{subsubsection.7.3.1.1}%
\contentsline {subsubsection}{\numberline {7.3.1.2}Pretraining}{27}{subsubsection.7.3.1.2}%
\contentsline {subsubsection}{\numberline {7.3.1.3}Burn-in length}{27}{subsubsection.7.3.1.3}%
\contentsline {subsubsection}{\numberline {7.3.1.4}Number of model parameters}{27}{subsubsection.7.3.1.4}%
\contentsline {subsection}{\numberline {7.3.2}Neutralino-Neutralino Cross Sections}{27}{subsection.7.3.2}%
\contentsline {chapter}{\numberline {8}Discussion}{29}{chapter.8}%
\contentsline {chapter}{Conclusion}{32}{chapter*.12}%
\contentsline {chapter}{Appendices}{33}{section*.13}%
\contentsline {chapter}{Appendix A}{35}{appendix*.14}%
\contentsline {section}{\numberline {A.1}Appendix 1 title }{35}{section.Alph0.1}%
